{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3yl99hOe_F3"
      },
      "source": [
        "# **😎 TensorFlow 年齡與性別估計（活頁簿 2：性別分類）**\n",
        "\n",
        "* 欲進行年齡估計，請至 [活頁簿 1（年齡估計）](https://colab.research.google.com/drive/1to2iolQGIVZgXFWRmRKZGrny5kfXk40h?usp=sharing)\n",
        "\n",
        "在本筆記本中，我們將訓練一個 Keras 模型，根據 *已裁剪人臉* 圖片來分類一個人的性別。我們使用著名的 [UTKFace 資料集](https://susanqq.github.io/UTKFace/)，該資料集包含 23,000 張影像，每張影像都標註了性別、年齡和族裔。\n",
        "\n",
        "> **注意：請確認您已連接到 Google Colab 的 GPU 執行環境，否則訓練可能需要非常長的時間。請至「執行階段 > 變更執行類型 > 硬體加速器」中啟用 GPU。**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMlbjEzffKQP"
      },
      "source": [
        "## 1) **下載 UTKFace 資料集** 💻\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnTGjqN2o_Z3"
      },
      "source": [
        "UTKFace 資料集可透過以下 Google 雲端硬碟資料夾取得：[連結](https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE)。請下載並將其放入您的 Google 雲端硬碟中。\n",
        "\n",
        "完成後，請在本筆記本中掛載您的 Google 雲端硬碟。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PKqk30bZ1Z6"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj0md65mfR5_"
      },
      "source": [
        "將 `utkface_23k.zip` 檔案解壓縮到本地目錄。這樣可以大幅提升影像解析的速度。詳情請參考 StackOverflow 的 [這篇回答](https://stackoverflow.com/a/60802388/10878733)。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SzwQHuZsiAsr"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Replace with your path!\n",
        "!unzip -q /content/drive/MyDrive/Datasets/utkface_23k.zip -d data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKFRvNVZfXT9"
      },
      "source": [
        "將資料夾名稱從 `utkace_23k` 更改為 `utkface23k`，以移除底線，避免在拆分檔名（解析年齡）時發生錯誤。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEptd_PoO6Qz"
      },
      "outputs": [],
      "source": [
        "\n",
        "!mv data/utkface_23k data/utkface23k\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eb_CNn_ui6QT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# # To download checkpoints, Keras models, TFLite models\n",
        "# from google.colab import files\n",
        "\n",
        "# Life is incomplete without this statement!\n",
        "import tensorflow as tf\n",
        "\n",
        "# And this as well!\n",
        "import numpy as np\n",
        "\n",
        "# To visualize results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAgOhn0cfrkg"
      },
      "source": [
        "## 2) **資料處理** 🦾\n",
        "\n",
        "下載資料集後，我們需要對其執行下列操作，以便用於模型訓練：\n",
        "\n",
        "* 👉🏻 讀取影像檔並轉成 3 維 NumPy 陣列。注意，我們將使用三通道 RGB 影像進行訓練，因此每個陣列的形狀為 `[影像寬度, 影像高度, 3]`。  \n",
        "* 👉🏻 拆分檔名以解析影像中人物的性別。我們使用 `tf.strings.split()` 方法來完成此任務。  \n",
        "* 👉🏻 將性別進行 one-hot 編碼，因為我們要執行**二分類**任務。\n",
        "\n",
        "完成上述步驟後，將得到 N 個樣本，每個樣本包含影像陣列（形狀 `[128, 128, 3]`）及其對應的 one-hot 編碼標籤（形狀 `[1, 2]`）。\n",
        "\n",
        "我們使用 `tf.data.Dataset` 來加速資料處理，以利平行運算。上述操作會透過 `tf.data.Dataset.map` 方法，映射到每個檔名上進行處理。  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m67XqZMHirhz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[00] image.shape = (128, 128, 3), gender_onehot = [0. 1.]\n",
            "[01] image.shape = (128, 128, 3), gender_onehot = [0. 1.]\n",
            "[02] image.shape = (128, 128, 3), gender_onehot = [0. 1.]\n",
            "[03] image.shape = (128, 128, 3), gender_onehot = [0. 1.]\n",
            "[04] image.shape = (128, 128, 3), gender_onehot = [1. 0.]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ----------------------------------------\n",
        "# 參數設定\n",
        "# ----------------------------------------\n",
        "MODEL_INPUT_IMAGE_SIZE = [128, 128]\n",
        "TRAIN_TEST_SPLIT       = 0.3\n",
        "NUM_SAMPLES            = 20000\n",
        "\n",
        "# ----------------------------------------\n",
        "# 建立資料夾路徑（參考第二段程式）\n",
        "# ----------------------------------------\n",
        "try:\n",
        "    BASE_DIR = Path(__file__).resolve().parent\n",
        "except NameError:\n",
        "    BASE_DIR = Path.cwd()\n",
        "\n",
        "PROJECT_ROOT = BASE_DIR.parent\n",
        "UTKFACE_DIR  = PROJECT_ROOT / \"dataset\" / \"archive\" / \"UTKFace\"\n",
        "\n",
        "if not UTKFACE_DIR.exists():\n",
        "    raise FileNotFoundError(f\"找不到資料夾：{UTKFACE_DIR}\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# One-hot 編碼向量\n",
        "# ----------------------------------------\n",
        "y1 = tf.constant([1., 0.], dtype='float32')\n",
        "y2 = tf.constant([0., 1.], dtype='float32')\n",
        "\n",
        "# ----------------------------------------\n",
        "# 影像解析函式（依原第一段程式）\n",
        "# ----------------------------------------\n",
        "def parse_image(filename):\n",
        "    image_raw = tf.io.read_file(filename)\n",
        "    image     = tf.image.decode_jpeg(image_raw, channels=3)\n",
        "    image     = tf.image.resize(image, MODEL_INPUT_IMAGE_SIZE) / 255.0\n",
        "\n",
        "    # 取出純檔名\n",
        "    fname = tf.strings.split(filename, os.sep)[-1]\n",
        "    parts = tf.strings.split(fname, \"_\")\n",
        "    # parts[1] 是性別 (0 or 1)\n",
        "    gender = tf.strings.to_number(parts[1], out_type=tf.float32)\n",
        "    gender_onehot = (gender * y2) + ((1 - gender) * y1)\n",
        "\n",
        "    return image, gender_onehot\n",
        "\n",
        "# ----------------------------------------\n",
        "# 建立 Dataset\n",
        "# ----------------------------------------\n",
        "pattern = str(UTKFACE_DIR / \"*.jpg\")   # 或 \"*.chip.jpg\" 視你資料命名而定\n",
        "list_ds = tf.data.Dataset.list_files(pattern, shuffle=True)\n",
        "\n",
        "dataset = (\n",
        "    list_ds\n",
        "    .map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    .take(NUM_SAMPLES)\n",
        ")\n",
        "\n",
        "# ----------------------------------------\n",
        "# 範例：列印前 5 筆\n",
        "# ----------------------------------------\n",
        "for idx, (img, lbl) in enumerate(dataset.take(5)):\n",
        "    print(f\"[{idx:02d}] image.shape = {img.shape}, gender_onehot = {lbl.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNm64KUSfzwj"
      },
      "source": [
        "\n",
        "我們會從資料集中建立兩個切分，一個用於訓練模型，另一個用於測試模型。測試資料的比例由 `TRAIN_TEST_SPLIT` 決定。  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E9aO3SH22mFK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num examples in train ds 14000\n",
            "Num examples in test ds 6000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create train and test splits of the dataset.\n",
        "num_examples_in_test_ds = int( dataset.cardinality().numpy() * TRAIN_TEST_SPLIT )\n",
        "\n",
        "test_ds = dataset.take( num_examples_in_test_ds )\n",
        "train_ds = dataset.skip( num_examples_in_test_ds )\n",
        "\n",
        "print( 'Num examples in train ds {}'.format( train_ds.cardinality() ) )\n",
        "print( 'Num examples in test ds {}'.format( test_ds.cardinality() ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZnNB0Nm3g_"
      },
      "source": [
        "## 3) **CNN 模型** 👨‍🎓\n",
        "\n",
        "我們的目標是設計一個參數更少（意味著推論時間與模型大小更小），但仍具有強大表現力以提升泛化能力的模型。\n",
        "\n",
        "* 👉🏻 模型接受形狀為 `[None, 128, 128, 3]` 的輸入批次，並依據 `num_blocks` 執行多層捲積運算。  \n",
        "* 👉🏻 每個 Block 包含以下層序列：`Conv2D → BatchNorm → LeakyReLU`  \n",
        "\n",
        "\n",
        "```\n",
        "# Define the conv block.\n",
        "if lite_model:\n",
        "        x = tf.keras.layers.SeparableConv2D( num_filters ,\n",
        "                                            kernel_size=kernel_size ,\n",
        "                                            strides=strides\n",
        "                                            , use_bias=False ,\n",
        "                                            kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                             )( x )\n",
        "    else:\n",
        "        x = tf.keras.layers.Conv2D( num_filters ,\n",
        "                                   kernel_size=kernel_size ,\n",
        "                                   strides=strides ,\n",
        "                                   use_bias=False ,\n",
        "                                   kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                   kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                    )( x )\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\n",
        "    x = tf.keras.layers.LeakyReLU( leaky_relu_alpha )( x )\n",
        "```\n",
        "\n",
        "* 若將 `lite_model` 設為 `True`，則使用[可分離捲積（Separable Convolutions）](https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728)，可減少參數數量，以換取更快速的推論速度，代價是可能略微犧牲效能。\n",
        "\n",
        "* 👉🏻 我們依序堆疊 `num_blocks` 個此類 Block，各層的過濾器數量由 `num_filters` 決定。\n",
        "\n",
        "* 👉🏻 接著加入多層 `Dense` 全連接層，以學習由捲積層所提取的特徵；同時插入 `Dropout` 層以減少過擬合。每層 `Dropout` 的 `rate` 會逐層遞減，確保單位數較少的全連接層仍具備良好可學習性。\n",
        "\n",
        "\n",
        "```\n",
        "def dense( x , filters , dropout_rate ):\n",
        "    x = tf.keras.layers.Dense( filters , kernel_regularizer=tf.keras.regularizers.L2( 0.1 ) , bias_regularizer=tf.keras.regularizers.L2( 0.1 ) )( x )\n",
        "    x = tf.keras.layers.LeakyReLU( alpha=leaky_relu_alpha )( x )\n",
        "    x = tf.keras.layers.Dropout( dropout_rate )( x )\n",
        "    return x\n",
        "```\n",
        "\n",
        "* 👉🏻 最後一個 `Dense` 層使用 softmax 激活函數，輸出 `male` 與 `female` 兩類的機率分布。\n",
        "\n",
        "> 如需選擇前述兩個區塊中所使用的權重衰減值，請參考 [這篇部落格](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/)。\n",
        "\n",
        "* 👉🏻 模型的輸出為形狀 `[None, 2]` 的張量。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_qmw6DHVG2QD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Negative slope coefficient for LeakyReLU.\n",
        "leaky_relu_alpha = 0.2\n",
        "\n",
        "lite_model = True\n",
        "\n",
        "# Define the conv block.\n",
        "def conv( x , num_filters , kernel_size=( 3 , 3 ) , strides=1 ):\n",
        "    if lite_model:\n",
        "        x = tf.keras.layers.SeparableConv2D( num_filters ,\n",
        "                                            kernel_size=kernel_size ,\n",
        "                                            strides=strides,\n",
        "                                            use_bias=False ,\n",
        "                                            kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                            kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                             )( x )\n",
        "    else:\n",
        "        x = tf.keras.layers.Conv2D( num_filters ,\n",
        "                                   kernel_size=kernel_size ,\n",
        "                                   strides=strides ,\n",
        "                                   use_bias=False ,\n",
        "                                   kernel_initializer=tf.keras.initializers.HeNormal() ,\n",
        "                                   kernel_regularizer=tf.keras.regularizers.L2( 1e-5 )\n",
        "                                    )( x )\n",
        "\n",
        "    x = tf.keras.layers.BatchNormalization()( x )\n",
        "    x = tf.keras.layers.LeakyReLU( leaky_relu_alpha )( x )\n",
        "    return x\n",
        "\n",
        "def dense( x , filters , dropout_rate ):\n",
        "    x = tf.keras.layers.Dense( filters , kernel_regularizer=tf.keras.regularizers.L2( 0.1 ) , bias_regularizer=tf.keras.regularizers.L2( 0.1 ) )( x )\n",
        "    x = tf.keras.layers.LeakyReLU( alpha=leaky_relu_alpha )( x )\n",
        "    x = tf.keras.layers.Dropout( dropout_rate )( x )\n",
        "    return x\n",
        "\n",
        "\n",
        "# No. of convolution layers to be added.\n",
        "num_blocks = 5\n",
        "# Num filters for each conv layer.\n",
        "num_filters = [ 16 , 32 , 64 , 128 , 256 , 256 ]\n",
        "# Kernel sizes for each conv layer.\n",
        "kernel_sizes = [ 3 , 3 , 3 , 3 , 3 , 3 ]\n",
        "\n",
        "# Init a Input Layer.\n",
        "inputs = tf.keras.layers.Input( shape=MODEL_INPUT_IMAGE_SIZE + [ 3 ] )\n",
        "\n",
        "# Add conv blocks sequentially\n",
        "x = inputs\n",
        "for i in range( num_blocks ):\n",
        "    x = conv( x , num_filters=num_filters[ i ] , kernel_size=kernel_sizes[ i ] )\n",
        "    x = tf.keras.layers.MaxPooling2D()( x )\n",
        "\n",
        "# Flatten the output of the last Conv layer.\n",
        "x = tf.keras.layers.Flatten()( x )\n",
        "conv_output = x\n",
        "\n",
        "# Add Dense layers ( Dense -> LeakyReLU -> Dropout )\n",
        "x = dense( conv_output , 256 , 0.6 )\n",
        "x = dense( x , 64 , 0.4 )\n",
        "x = dense( x , 32 , 0.2 )\n",
        "outputs = tf.keras.layers.Dense( 2 , activation='softmax' )( x )\n",
        "\n",
        "# Build the Model\n",
        "model = tf.keras.models.Model( inputs , outputs )\n",
        "\n",
        "# Uncomment the below to view the summary of the model.\n",
        "# model.summary()\n",
        "# tf.keras.utils.plot_model( model , to_file='architecture.png' )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yobN_O2S3en9"
      },
      "source": [
        "執行此程式區塊，以在本筆記本中直接使用 TensorBoard 可視化模型訓練過程。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ycIUYrp65w7r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 34752), started 1:28:29 ago. (Use '!kill 34752' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-2673850240d46fea\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-2673850240d46fea\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tb_logs/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JMUGVWqgAdR"
      },
      "source": [
        "```markdown\n",
        "## 4) **編譯模型（及其他 Callback）** 🧱\n",
        "\n",
        "定義完模型架構後，我們將編譯 Keras 模型並初始化一些有用的 Callback。\n",
        "\n",
        "* 👉🏻 由於我們進行的是分類任務，因此使用「分類交叉熵（Categorical Crossentropy）」作為損失函數。詳情請參考 [`tf.keras.losses.CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)。\n",
        "\n",
        "* 👉🏻 使用 Adam 優化器來訓練模型。詳情請參考 [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)。\n",
        "\n",
        "* 👉🏻 為了評估模型效能，我們使用「準確率（Accuracy）」作為評估指標。詳情請參考 [`tf.keras.metrics.Accuracy`](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/Accuracy)。\n",
        "\n",
        "#### Callback：\n",
        "\n",
        "* 👉🏻 [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint)：在每個 epoch 結束後，將模型儲存為 H5 檔案。\n",
        "\n",
        "* 👉🏻 [`tf.keras.callbacks.TensorBoard`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard)：使用 TensorBoard 可視化訓練過程。\n",
        "\n",
        "* 👉🏻 [`tf.keras.callbacks.EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping)：當測試資料集上的評估指標（即準確率）不再改善時，停止訓練。\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cow71DK6kjUQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 10\n",
        "batch_size = 128\n",
        "\n",
        "train_ds = train_ds.batch( batch_size ).repeat( num_epochs )\n",
        "test_ds = test_ds.batch( batch_size ).repeat( num_epochs )\n",
        "\n",
        "save_dir = 'train-1/cp.ckpt'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( save_dir )\n",
        "\n",
        "logdir = os.path.join( \"tb_logs\" , datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") )\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard( logdir )\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping( monitor='val_accuracy' , patience=3 )\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy ,\n",
        "    optimizer = tf.keras.optimizers.Adam( learning_rate ) ,\n",
        "    metrics =[ 'accuracy' ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtpRh9y0orKo"
      },
      "source": [
        "## 5) **訓練與評估模型** 🏋🏻‍♂️\n",
        "\n",
        "將所有 Callback 一次打包後，開始執行訓練迴圈。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RddzZAhSgTQ5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1100/1100 [==============================] - 321s 283ms/step - loss: 15.3655 - accuracy: 0.7273 - val_loss: 2.3786 - val_accuracy: 0.8348\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 2/10\n",
            "1100/1100 [==============================] - 295s 266ms/step - loss: 1.2156 - accuracy: 0.8446 - val_loss: 0.6260 - val_accuracy: 0.8716\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 3/10\n",
            "1100/1100 [==============================] - 282s 254ms/step - loss: 0.5131 - accuracy: 0.8715 - val_loss: 0.4197 - val_accuracy: 0.8832\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 4/10\n",
            "1100/1100 [==============================] - 313s 283ms/step - loss: 0.4051 - accuracy: 0.8869 - val_loss: 0.3569 - val_accuracy: 0.9039\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 5/10\n",
            "1100/1100 [==============================] - 332s 300ms/step - loss: 0.3648 - accuracy: 0.8995 - val_loss: 0.3273 - val_accuracy: 0.9166\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 6/10\n",
            "1100/1100 [==============================] - 339s 306ms/step - loss: 0.3327 - accuracy: 0.9129 - val_loss: 0.2952 - val_accuracy: 0.9313\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 7/10\n",
            "1100/1100 [==============================] - 321s 289ms/step - loss: 0.3072 - accuracy: 0.9236 - val_loss: 0.2768 - val_accuracy: 0.9389\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 8/10\n",
            "1100/1100 [==============================] - 285s 257ms/step - loss: 0.2830 - accuracy: 0.9339 - val_loss: 0.2514 - val_accuracy: 0.9494\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 9/10\n",
            "1100/1100 [==============================] - 267s 241ms/step - loss: 0.2619 - accuracy: 0.9432 - val_loss: 0.2262 - val_accuracy: 0.9615\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n",
            "Epoch 10/10\n",
            "1100/1100 [==============================] - 288s 260ms/step - loss: 0.2422 - accuracy: 0.9516 - val_loss: 0.2091 - val_accuracy: 0.9673\n",
            "INFO:tensorflow:Assets written to: train-1\\cp.ckpt\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f645ac1a90>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "model.fit(\n",
        "    train_ds,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=test_ds, callbacks=[ checkpoint_callback , tensorboard_callback , early_stopping_callback ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WVYKruLozh4"
      },
      "source": [
        "評估模型。  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tffNBtPQBTX1"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load pretrained model ( if required )\n",
        "model = tf.keras.models.load_model( 'model_gender.h5' )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "41vGSd6qDvtb"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "# Unbatch the dataset first.\n",
        "test_ds = test_ds.unbatch()\n",
        "for image , label in test_ds.as_numpy_iterator():\n",
        "    test_images.append( image )\n",
        "    test_labels.append( label )\n",
        "\n",
        "# Converts lists to ndarrays\n",
        "test_images = np.array( test_images )\n",
        "test_labels = np.array( test_labels )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aZKpG-IVBr_C"
      },
      "outputs": [
        {
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m( \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m accuracy is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat( p[\u001b[38;5;241m0\u001b[39m] , p[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m ) )\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\training.py:1466\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1463\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1466\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1468\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1469\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1470\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1471\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1472\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1473\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1474\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1383\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1382\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1138\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1137\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:230\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    220\u001b[0m              x,\n\u001b[0;32m    221\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    228\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    229\u001b[0m   \u001b[38;5;28msuper\u001b[39m(TensorLikeDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 230\u001b[0m   x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m   sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[0;32m    232\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[0;32m    234\u001b[0m   \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1031\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[0;32m   1029\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m-> 1031\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_and_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1026\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1024\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[0;32m   1025\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m-> 1026\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[0;32m   1028\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1430\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m   1369\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \n\u001b[0;32m   1372\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1430\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1436\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1436\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ],
      "source": [
        "\n",
        "p = model.evaluate( test_images , test_labels )\n",
        "print( 'loss is {} \\n accuracy is {} %'.format( p[0] , p[1] * 100 ) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyQxoxoJCryI"
      },
      "outputs": [
        {
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report , confusion_matrix , ConfusionMatrixDisplay\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Fetch model predictions for test_x\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the classification report\u001b[39;00m\n\u001b[0;32m      7\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report( np\u001b[38;5;241m.\u001b[39margmax( test_labels , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m ) , np\u001b[38;5;241m.\u001b[39margmax( pred_y , axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m ) , target_names\u001b[38;5;241m=\u001b[39m[ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmale\u001b[39m\u001b[38;5;124m'\u001b[39m , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m'\u001b[39m ] )\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\training.py:1720\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUsing Model.predict with \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1716\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiWorkerDistributionStrategy or TPUStrategy and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1717\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoShardPolicy.FILE might lead to out-of-order result\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1718\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1720\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1383\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1382\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1138\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1137\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:230\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    220\u001b[0m              x,\n\u001b[0;32m    221\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    228\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    229\u001b[0m   \u001b[38;5;28msuper\u001b[39m(TensorLikeDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 230\u001b[0m   x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m   sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[0;32m    232\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[0;32m    234\u001b[0m   \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1031\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[0;32m   1029\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m-> 1031\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_and_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\keras\\engine\\data_adapter.py:1026\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1024\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[0;32m   1025\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m-> 1026\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[0;32m   1028\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1430\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m   1369\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \n\u001b[0;32m   1372\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1430\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1436\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1435\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1436\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
            "File \u001b[1;32md:\\Miniconda\\envs\\tf-gpu-palm\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import classification_report , confusion_matrix , ConfusionMatrixDisplay\n",
        "\n",
        "# Fetch model predictions for test_x\n",
        "pred_y = model.predict( test_images )\n",
        "\n",
        "# Print the classification report\n",
        "report = classification_report( np.argmax( test_labels , axis=1 ) , np.argmax( pred_y , axis=1 ) , target_names=[ 'male' , 'female' ] )\n",
        "print( report )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwvBPtWFC9Hy"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot the confusion matrix\n",
        "conf_matrix = confusion_matrix( np.argmax( test_labels , axis=1 ) ,np.argmax( pred_y , axis=1 ) )\n",
        "disp = ConfusionMatrixDisplay( conf_matrix , display_labels=[ 'male' , 'female' ] )\n",
        "disp.plot()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spX1Piedo0-X"
      },
      "source": [
        "\n",
        "將 Keras 模型儲存到本機磁碟，以便日後需要時能夠續訓。  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "m5TtLuHZDFry"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = 'model_gender' #@param {type: \"string\"}\n",
        "model_name_ = model_name + '.h5'\n",
        "\n",
        "model.save( model_name_ )\n",
        "# files.download( model_name_ )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTw5UugS8epl"
      },
      "source": [
        "## 6) **可視化結果**\n",
        "\n",
        "我們將從 `test_ds` 中取出一些影像進行性別預測，並使用 `matplotlib` 繪製結果。  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NH_O8ZEQ8i85"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image , label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m( test_images[ \u001b[38;5;241m0\u001b[39m : \u001b[38;5;241m10\u001b[39m ] , test_labels[ \u001b[38;5;241m0\u001b[39m : \u001b[38;5;241m10\u001b[39m ] ):\n\u001b[1;32m----> 8\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n\u001b[0;32m      9\u001b[0m     fig\u001b[38;5;241m.\u001b[39madd_subplot( rows , columns , i )\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow( image )\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'numpy'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1200x1500 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "fig = plt.figure( figsize=( 12 , 15 ) )\n",
        "classes = [ 'Male' , 'Female' ]\n",
        "rows = 5\n",
        "columns = 2\n",
        "\n",
        "i = 1\n",
        "for image , label in zip( test_images[ 0 : 10 ] , test_labels[ 0 : 10 ] ):\n",
        "    image = image.numpy()\n",
        "    fig.add_subplot( rows , columns , i )\n",
        "    plt.imshow( image )\n",
        "    label_ = classes[ np.argmax( model.predict( np.expand_dims( image , 0 ) ) ) ]\n",
        "    plt.axis( 'off' )\n",
        "    plt.title( 'Predicted gender : {} , actual gender : {}'.format( label_ , classes[ np.argmax( label ) ] ) )\n",
        "    i += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSOFJqsf-uK9"
      },
      "source": [
        "## 7) **轉換為 TensorFlow Lite 格式** 📡\n",
        "\n",
        "我們的模型將部署在 Android 應用程式中，會使用 [TF Lite Android](https://bintray.com/google/tensorflow/tensorflow-lite) 套件來載入模型並進行推論。\n",
        "\n",
        "我們使用 `TFLiteConverter` API 將 Keras 模型（`.h5`）轉換為 TF Lite 緩衝區（`.tflite`）。詳見官方文件：[TFLiteConverter](https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter/)。  \n",
        "最終會產出兩個 TF Lite 檔案：  \n",
        "1. 使用 float16 量化的版本  \n",
        "2. 未量化的版本  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ZwmMTQxyhToJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\chenk\\AppData\\Local\\Temp\\tmp5ve30i1p\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "669312"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n",
        "converter.target_spec.supported_types = [ tf.float16 ]\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_q.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "# files.download( '{}_q.tflite'.format( model_name ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5VTeSnGAhm_"
      },
      "source": [
        "將模型轉換為未量化的 TF Lite 緩衝區。  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "9jnurapqK6fw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\chenk\\AppData\\Local\\Temp\\tmp4q8s40h8\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\chenk\\AppData\\Local\\Temp\\tmp4q8s40h8\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "1319560"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model( model )\n",
        "buffer = converter.convert()\n",
        "\n",
        "open( '{}_nonq.tflite'.format( model_name ) , 'wb' ).write( buffer )\n",
        "# files.download( '{}_nonq.tflite'.format( model_name ) )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uQcN2eMkrR5"
      },
      "source": [
        "\n",
        "## Utility Methods\n",
        "\n",
        "Use these methods to automate some of the tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGGdHh5oEtK1"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Utility to zip and download a directory\n",
        "#@markdown Use this method to zip and download a directory. For ex. a TB logs\n",
        "#@markdown directory or a checkpoint(s) directory.\n",
        "\n",
        "dir_to_zip = 'tb_logs' #@param {type: \"string\"}\n",
        "output_filename = 'logs.zip' #@param {type: \"string\"}\n",
        "delete_dir_after_download = \"No\"  #@param ['Yes', 'No']\n",
        "\n",
        "os.system( \"zip -r {} {}\".format( output_filename , dir_to_zip ) )\n",
        "\n",
        "if delete_dir_after_download == \"Yes\":\n",
        "    os.system( \"rm -r {}\".format( dir_to_zip ) )\n",
        "\n",
        "files.download( output_filename )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jGbWLjNXJMSt"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Utility to delete a directory\n",
        "#@markdown Use this method to delete a directory.\n",
        "\n",
        "dir_path = ''  #@param {type: \"string\"}\n",
        "os.system( f'rm -r {dir_path}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNaP2TMOq-tA"
      },
      "source": [
        "\n",
        "# LICENSE\n",
        "\n",
        "```\n",
        "  \n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2021 Shubham Panchal\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Gender_Estimation_(W2).ipynb",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "tf-gpu-palm",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
